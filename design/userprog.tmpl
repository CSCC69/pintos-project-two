             +--------------------------+
             | CSCC69                   |
             | PROJECT 2: USER PROGRAMS	|
             | DESIGN DOCUMENT          |
             +--------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Nathanael Robbins <nate.robbinss@mail.utoronto.ca>
Lucas Ilea <lucas.ilea@mail.utoronto.ca>
Louis Ren <louis.ren@mail.utoronto.ca>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

               ARGUMENT PASSING
               ================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> A2: Briefly describe how you implemented argument parsing.  How do
>> you arrange for the elements of argv[] to be in the right order?
>> How do you avoid overflowing the stack page?

Argument parsing is implemented by traversing the initial program command line and using strtok_r to parse the arguments into an array.
Then, we iterate backwards through that array and write them onto the stack in that order.

To avoid overflowing the stack page, we keep track of the length (in bytes) of each argument before we push it onto the stack. If there is no more stack space, we free the stack page and return false.
The same logic is used when pushing the addresses of each argument, and for the remaining stack arguments.

---- RATIONALE ----

>> A3: Why does Pintos implement strtok_r() but not strtok()?

Pintos implements strtok_r() but not strtok() because strtok_r() is a reentrant version of strtok().
This means that the function can be interrupted, resumed, and called again by different threads. This is especially important when writing kernel-level code in Pintos as the Pintos
kernel is preemptable, and these interruptions can introduce bugs and other issues when using the regular strtok() that uses global state to keep track of the string position.

>> A4: In Pintos, the kernel separates commands into a executable name
>> and arguments.  In Unix-like systems, the shell does this
>> separation.  Identify at least two advantages of the Unix approach.

                 SYSTEM CALLS
                 ============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

>> B2: Describe how file descriptors are associated with open files.
>> Are file descriptors unique within the entire OS or just within a
>> single process?

File descriptors are associated with each instance of an open file. When the open syscall is called, the "filesys" code locates the inode for the file, and returns a pointer to a "file" struct
for this instance. Each of these pointers are stored in a "fd_file" struct with an associated file descriptor. Then, the "fd_file" struct is inserted into the "fd_file_table" hash table
with the file descriptor as the key.

This fd_file_table is stored per process, meaning that file descriptors are only unique within a single process, not the entire OS. For example, two different processes can have different open
files associated with the same file descriptor.

---- ALGORITHMS ----

>> B3: Describe your code for reading and writing user data from the
>> kernel.

>> B4: Suppose a system call causes a full page (4,096 bytes) of data
>> to be copied from user space into the kernel.  What is the least
>> and the greatest possible number of inspections of the page table
>> (e.g. calls to pagedir_get_page()) that might result?  What about
>> for a system call that only copies 2 bytes of data?  Is there room
>> for improvement in these numbers, and how much?

To copy a full page of data from a user address into the kernel, there will be at most 2 calls to pagedir_get_page. This is because the 4096 bytes of data can be entirely within 1 page, or
split partway between two pages.

With 2 bytes of data, the number is the same - one byte in each page.

>> B5: Briefly describe your implementation of the "wait" system call
>> and how it interacts with process termination.

SYS_WAIT is handled as normal initially through our syscall_handler. We then call wait. If the pid is not valid (< 0) we return -1.
Otherwise, we return the value of process_wait().

We get the child via tid by iterating over the thread's child_list.

In process_wait(), we check if child's parent is not the current thread, or if the child is the current thread, or if the child is NULL.
If so, we just return -1 since we cannot wait here.

We try to sema_down/acquire a wait semaphore, as it will become available when the child releases its semaphore on exit.

We remove the child from the thread's list and then free it and its childrens allocated resources, and return its exit status.


>> B6: Any access to user program memory at a user-specified address
>> can fail due to a bad pointer value.  Such accesses must cause the
>> process to be terminated.  System calls are fraught with such
>> accesses, e.g. a "write" system call requires reading the system
>> call number from the user stack, then each of the call's three
>> arguments, then an arbitrary amount of user memory, and any of
>> these can fail at any point.  This poses a design and
>> error-handling problem: how do you best avoid obscuring the primary
>> function of code in a morass of error-handling?  Furthermore, when
>> an error is detected, how do you ensure that all temporarily
>> allocated resources (locks, buffers, etc.) are freed?  In a few
>> paragraphs, describe the strategy or strategies you adopted for
>> managing these issues.  Give an example.

To avoid cluttering up system calls with error handling, and the need to free temporarily allocated resources during the execution of a system call, we simply verify all user-specified addresses *before*
calling into the system call implementation. If any addresses are invalid, the user program will exit.

As an example, consider the following call to the "create" system call.
create(0x12345678, 5)

After retrieving the stack pointer esp from the interrupt frame, we call verify_stack_pointer_word to ensure that the stack pointer (and 3 bytes past it) are valid. In this case,
only the address stored at esp is invalid, so we extract the system call number and continue.

The "create" system call takes 2 arguments, so we call stack_pop, verify 4 consecutive stack addresses, and place the esp value for the start of each argument in an array, to be dereferenced later.

To extract the address storing the file name, we call verify_user_pointer_word. Since the address 0x12345678 causes a page fault when dereferenced (handling described in B9), we call exit()
and do not being system call execution.

---- SYNCHRONIZATION ----

>> B7: The "exec" system call returns -1 if loading the new executable
>> fails, so it cannot return before the new executable has completed
>> loading.  How does your code ensure this?  How is the load
>> success/failure status passed back to the thread that calls "exec"?

When a new thread is created, it holds a semaphore called "exec_sema" that is initialized to a value of 0, meaning that no threads can acquire/sema down it.
When the "exec" system call has finished calling process_execute, it then attempts to acquire "exec_sema" from the newly executed thread.
This will block the "exec" system call until the thread being created releases/calls sema up on "exec_sema", which it does once it has either successfully loaded or failed to load the executable.
Then, the "exec" system call will be able to acquire the semaphore, and finally return the PID.

>> B8: Consider parent process P with child process C.  How do you
>> ensure proper synchronization and avoid race conditions when P
>> calls wait(C) before C exits?  After C exits?  How do you ensure
>> that all resources are freed in each case?  How about when P
>> terminates without waiting, before C exits?  After C exits?  Are
>> there any special cases?

When P calls wait(C) before C exits we have a semaphore (wait_sema) that is sema_down/acquired when
process_wait is called. The thread will try to acquire the semaphore and will wait until it exits.
In thread_exit the semaphore is released and then process_wait can continue.

In process_wait we call free_thread_and_childs() which will free the fd_file structs and
destroy the respective child's hash table for children in the thread's list that are dying.
Then it will recurse and do the same for the children.
For the threads that are not dying, we set their parent to null.
In the case that the parent exits without waiting,
the children are iterated over and then we perform the same process on children that aren't running.
Whenever a thread exits, we also check if the parent has exited and if it has then we free self and children
that are dying. If the parent hasn't exited we leave the thread struct intact so the parent can sequentially
wait on it.

---- RATIONALE ----

>> B9: Why did you choose to implement access to user memory from the
>> kernel in the way that you did?

We chose to safely access user memory with the page fault approach. When a syscall is triggered, we verify both that the stack pointer itself is valid
(in user memory and dereferenceable without page fault), and then that the user memory address stored at that stack address is valid (in user memory and dereferenceable
without page fault, using the provided get_user function.) If a page fault is triggered, the page fault handler returns -1, which we detect and then call exit().

We verify all arguments before calling our syscall implementations, which has many advantages described in question B6.

>> B10: What advantages or disadvantages can you see to your design
>> for file descriptors?

The advantage of our design for file descriptors, which is storing the fd->open file mappings in a hash table, means that we don't need to impose a limit on the maximum number of possible file descriptors
that a process can have open, like would be the case with an array. It also allows for O(1) time lookup for open files using the file descriptor as a key, which wouldn't be possible if we were
to use a linked list to store this mapping.

Further advantages to our design include reusing file descriptors once they're closed, meaning we can assign file descriptors sequentially and not have to perform calculations or casts to get a file descriptor.

>> B11: The default tid_t to pid_t mapping is the identity mapping.
>> If you changed it, what advantages are there to your approach?

We did not change this mapping.

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
